\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The two basis functions $N_{2k+1}$ and $N_{2k+2}$ on interval $[t_k, t_{k+2})$. It is apparently that these basis functions are continuous on this interval and have continuous first derivatives.\relax }}{14}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Numerical example: $\textit {Blocks}$. (a) The true velocity function. (b) Velocity with Gaussian noise at SNR=7. (c) Generated position function. (d) Position with Gaussian noise at SNR=7. (e) Reconstruction from Wavelet with sure threshold. (f) Reconstruction from Wavelet with BayesThresh approach. (g) Reconstruction by P-spline. (h) Reconstruction by tractor spline setting $\gamma =0$. (i) Reconstruction by tractor spline with normal penalty term. (j) Reconstruction by proposed tractor spline.\relax }}{21}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Numerical example: $\textit {Bumps}$. (a) The true velocity function. (b) Velocity with Gaussian noise at SNR=7. (c) Generated position function. (d) Position with Gaussian noise at SNR=7. (e) Reconstruction from Wavelet with sure threshold. (f) Reconstruction from Wavelet with BayesThresh approach. (g) Reconstruction by P-spline. (h) Reconstruction by tractor spline setting $\gamma =0$. (i) Reconstruction by tractor spline with normal penalty term. (j) Reconstruction by proposed tractor spline.\relax }}{22}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Numerical example: $\textit {HeaviSine}$. (a) The true velocity function. (b) Velocity with Gaussian noise at SNR=7. (c) Generated position function. (d) Position with Gaussian noise at SNR=7. (e) Reconstruction from Wavelet with sure threshold. (f) Reconstruction from Wavelet with BayesThresh approach. (g) Reconstruction by P-spline. (h) Reconstruction by tractor spline setting $\gamma =0$. (i) Reconstruction by tractor spline with normal penalty term. (j) Reconstruction by proposed tractor spline.\relax }}{23}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Numerical example: $\textit {Doppler}$. (a) The true velocity function. (b) Velocity with Gaussian noise at SNR=7. (c) Generated position function. (d) Position with Gaussian noise at SNR=7. (e) Reconstruction from Wavelet with sure threshold. (f) Reconstruction from Wavelet with BayesThresh approach. (g) Reconstruction by P-spline. (h) Reconstruction by tractor spline setting $\gamma =0$. (i) Reconstruction by tractor spline with normal penalty term. (j) Reconstruction by proposed tractor spline.\relax }}{24}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Estimated penalty functions. Left side shows how the value of $\lambda (t)$ changes on the interval. Right side projects $\lambda (t)$ into reconstructions. The bigger the blacks dots present, the larger the penalty values are.\relax }}{25}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Estimated velocity functions by taking the first derivative of tractor spline. (a) Fitted $\mathit {Blocks}$. (b) Fitted $\mathit {Bumps}$. (c) Fitted $\mathit {HeaviSine}$. (d) Fitted $\mathit {Doppler}$.\relax }}{26}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) Comparing two methods under the same parameters $\lambda =0.01$ and $\gamma =0.1$. In this graph, the blue line is reconstruction from tractor spline, the red line is the mean of Gaussian Process, which is the posterior $\mathbb {E}(f(x) \mid \mathbf {Y}, \mathbf {V})$. (b) The differences between two methods under the same parameters.\relax }}{38}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Examples of 2-Dimension Random Walk Metropolis-Hastings algorithm. Figure (a) is using one-variable-at-a-time proposal Random Walk. At each time, only one variable is changed and the other one stay constant. Figure (b) and (c) are using multi-variable-at-a-time Random Walk. The difference is in figure (b), every forward step are proposed independently, but in (c) are proposed according to the covariance matrix. \relax }}{63}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Metropolis algorithm sampling for a single parameter with (a) a large step size, (b) a small step size, (c) an appropriate step size. The upper plots show the sample chain and lower plots indicate the autocorrelation for each case.\relax }}{66}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Linear simulation with true parameter $\theta = \{\phi =0.9,\tau ^2=0.5,\sigma ^2=1\}$. By transforming to original scale, the estimation is $\mathaccentV {hat}05E{\theta }=\{ \phi = 0.8810, \tau ^2 = 0.5247,\sigma ^2= 0.9416\}$. \relax }}{71}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Linear simulation of $x_{1:t}$ and sole $x_t$.In sub-figure (a), the dots is the true $x_{1:t}$ and the solid line is the estimation $\mathaccentV {hat}05E{x}_{1:t}$. In sub-figure (b), the chain in solid line is the estimation $\mathaccentV {hat}05E{x}_t$; dotted line is the true value of $x$; dot-dash line on top is the observed value of $y$; dashed lines are the estimated error. \relax }}{74}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Simulated data. The circle dots are the true state $x_{1:t}$ and cross dots are observations $y_{1:t}$. Irregular time lag $\Delta _t$ are generated from \textit {Inverse Gamma}(2,0.1) distribution.\relax }}{76}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Irregular time step OU process simulation. The estimation of $\mathaccentV {hat}05E{\theta }$ is $\{\gamma =0.4841, \lambda ^2=0.1032, \sigma ^2=0.9276\}$. In the plots, the horizontal dark lines are the true $\theta $. \relax }}{77}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Irregular time step OU process simulation of $x_{1:t}$ and sole $x_t$. In sub-figure (a), the dots is the true $x_{1:t}$ and the solid line is the estimation $\mathaccentV {hat}05E{x}_{1:t}$. In sub-figure (b), the chain in solid line is the estimation $\mathaccentV {hat}05E{x}_t$; dotted line is the true value of $x$; dot-dash line on top is the observed value of $y$; dashed lines are the estimated error. \relax }}{79}
\contentsline {figure}{\numberline {5.8}{\ignorespaces The trajectory of a moving tractor. The time lags (right side figure) obtained from GPS units are irregular.\relax }}{79}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Probability density function and cumulative distribution function of \textit {Inverse Gamma} with two parameters $\alpha $ and $\beta $. \relax }}{86}
\contentsline {figure}{\numberline {5.10}{\ignorespaces An example of Eff, EUT, ESS and ESSUT found by using the same data. \relax }}{88}
\contentsline {figure}{\numberline {5.11}{\ignorespaces Comparison Eff, ESS, EffUT and ESSUT of different length of data. \relax }}{89}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Comparison $\qopname \relax o{ln}DA$ and $\qopname \relax o{ln}L$ between not-updating and updating mean methods. \relax }}{93}
\contentsline {figure}{\numberline {5.13}{\ignorespaces Comparison between not-updating and updating mean methods. \relax }}{94}
\contentsline {figure}{\numberline {5.14}{\ignorespaces Visualization of correlation matrix of $\theta $, which is found in learning-surface process. \relax }}{94}
\contentsline {figure}{\numberline {5.15}{\ignorespaces Trace plots of $\theta $ from learning surface process after taking 1\tmspace +\thinmuskip {.1667em}000 samples from 5\tmspace +\thinmuskip {.1667em}000. \relax }}{95}
\contentsline {figure}{\numberline {5.16}{\ignorespaces Position and velocity for $X$ and $Y$ found by combined batch and sequential methods. \relax }}{96}
\contentsline {figure}{\numberline {5.17}{\ignorespaces Zoom in on estimations. For each estimation $\mathaccentV {hat}05E{X}_i (i=1,\dots ,t)$, there is a error circle around it. \relax }}{97}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Synchronized Euclidean Distance\relax }}{102}
\contentsline {figure}{\numberline {6.2}{\ignorespaces (a) error measured at fixed sampling rate as sum of perpendicular distance chords; (b) error measured at fixed sampling rates as sum of time-synchronous distance chords.\relax }}{102}
\contentsline {figure}{\numberline {6.3}{\ignorespaces A segment start from time 2000 to 3000, recorded by GPS units. On the left side, it's the trajectory connected by raw data with 27 points. In the middle, it's the trajectory connected by simplified data with Douglas-Peucker Algorithm with 24 points. On the right side, it's the trajectory connected by simplified data with Tractor Simplification Algorithm with 23 points.\relax }}{104}
\contentsline {figure}{\numberline {6.4}{\ignorespaces Trajectory fitted by Adaptive Kalman Filter. The errors of raw data, DP and tractor algorithm caused by AKF is 26.89217, 23.97877 and 23.97097 respectively.\relax }}{104}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {B.1}{\ignorespaces Running the same amount of time and taking the same length of data, the step size $\epsilon =2.5$ returns the highest ESSUT value and generates more effective samples with a lower correlation. \relax }}{128}
\contentsline {figure}{\numberline {B.2}{\ignorespaces Impacts of data length on optimal parameter. \relax }}{129}
\contentsline {figure}{\numberline {B.3}{\ignorespaces Key features comparison. \relax }}{131}
\contentsline {figure}{\numberline {B.4}{\ignorespaces Parameter Comparison. \relax }}{132}
\contentsline {figure}{\numberline {B.5}{\ignorespaces Parameter Evolution Visualization. \relax }}{133}
\contentsline {figure}{\numberline {B.6}{\ignorespaces Parameter Evolution Visualization. \relax }}{134}
\contentsline {figure}{\numberline {B.7}{\ignorespaces Parameter Evolution Visualization. \relax }}{135}
\contentsline {figure}{\numberline {B.8}{\ignorespaces Parameter Evolution Visualization. \relax }}{136}
