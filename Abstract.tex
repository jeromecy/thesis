
Inference and characterization of planar trajectories have been problems that confusing researchers for years. Precise and efficient algorithms are highly demanded in all kinds of applications. 

Given a set of time series GPS data from a moving object, connecting location points consequently will represent the trajectory of an individual or a vehicle. However, sparse points and data errors will give a trajectory with angels, which are unlike for a moving object. Smoothing spline methods can efficiently build up a more smooth trajectory. In conventional smoothing spline, the objective function tries to minimize errors of locations with a penalty term, who has a single parameter that controls the smoothness of reconstruction. Adaptive smoothing spline extends single parameter to a function varying in different domains and adapting the change of roughness. In Chapter \ref{ChapterTS}, a new method is proposed and named V-spline, which incorporates both location and velocity information but penalizes excessive accelerations. The penalty term is dependent on mechanic boom status. A new parameter, which controls the errors of velocity, and adjusted penalty terms, which adapts to a more complicated curvature status, are introduced to the new objective function. Additionally, an extended cross-validation technique is utilized to find all the smoothing parameters of interest. It can be seen from simulated studies that the V-spline has a higher accuracy than other methods. At the end of this chapter, a real data example is presented to demonstrate the effectiveness of V-spline.


It has been proved that the Bayesian estimates with improper priors are corresponding to smoothing splines. By constructing a reproducing kernel Hilbert space with an appropriate inner product on $[0,1]$, the Bayesian estimates calculated by Gaussian process regression is as the same as conventional smoothing splines. In Chapter \ref{ChapterGPR}, the Bayesian form for a trivial V-spline, whose penalty parameter is a fixed constant instead of a function, was introduced. In the particular reproducing kernel Hilbert space, in which the second derivatives are piecewise continuous, the V-spline is corresponding to the posterior mean of the Bayesian estimates, even though with correlated errors. As an extension to generalized cross-validation, a modified GCV formula is utilized to find the optimal parameters. 


Chapter \ref{ChapterFR} takes a brief overview of existing filtering and estimation algorithms. It is well known that most algorithms for combined state and parameters estimation in state-space models either estimate the states and parameters by incorporating the parameters in the state-space, or by marginalizing out the parameters through sufficient statistics. Then in Chapter \ref{ChapterMCMC}, an adaptive Markov chain Monte Carlo algorithm is proposed. In the case of a linear state-space model and starting with a joint distribution over states, observations, and parameters, an MCMC sampler is implemented with two phases. In the learning phase, a self-tuning sampler is used to learn the parameter mean and covariance structure. In the estimation phase, the parameter mean and covariance structure informs the proposed mechanism and is also used in a delayed-acceptance algorithm, which greatly improves sampling efficiency. Information on the resulting state of the system is indicated by a Gaussian mixture. In the on-line mode, the algorithm is adaptive and uses a sliding window approach by cutting off historical data to accelerate sampling speed and to maintain applicable acceptance rates. This algorithm is applied to the joint state and parameters estimation in the case of irregularly sampled GPS time series data. 
