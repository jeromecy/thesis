
Inference and characterization of planar trajectories have been problems that confusing researchers for years. Precise and efficient algorithms are highly demanded in all kinds of applications. 

Given a set of time series GPS data from a moving object, connecting location points consequently will represent the trajectory of an individual or a vehicle. However, sparse points and data errors will give a trajectory with angels, which are unlike for a moving object. Smoothing spline methods can efficiently build up a more smooth trajectory. In conventional smoothing spline, the objective function tries to minimize errors of locations with a penalty term, who has a single parameter that controls the smoothness of reconstruction. Adaptive smoothing spline extends single parameter to a function varying in different domains and adapting the change of roughness. In Chapter \ref{ChapterTS}, a new method was proposed and named Tractor spline, that incorporates both location and velocity information but penalizes excessive accelerations. The penalty term is dependent on mechanic boom status. A new parameter, which controls the errors of velocity, and adjusted penalty terms, which adapts to a more complicated curvature status, are introduced to the new objective function. Additionally, an extended cross-validation techniques is used to find all the smoothing parameters of interest. It can be seen from simulated studies that the Tractor spline has a higher accuracy than other methods. At the end of the chapter, a real data example are presented to demonstrate the effectiveness of Tractor spline.


It has been proved that the Bayesian estimates with improper priors are corresponding to smoothing splines. By constructing a reproducing kernel Hilbert space with an appropriate inner product on $[0,1]$, the Bayesian estimates calculated by Gaussian process regression is as the same as conventional smoothing splines. In Chapter \ref{ChapterGPR}, the Bayesian form for a trivial Tractor spline, whose penalty parameter is a fixed constant instead of a function, was introduced. In the particular reproducing kernel Hilbert space, in which the second derivatives are piecewise continuous, the Tractor spline is corresponding to the posterior mean of the Bayesian estimates, even though with correlated errors. As an extension to generalized cross-validation, an modified GCV formula is used to find the optimal parameters. 


Chapter \ref{ChapterFR} takes a brief overview on existing filtering and estimation algorithms. It is known that most algorithms for combined state and parameters estimation in state space models either estimate the states and parameters by incorporating the parameters in the state space, or by marginalizing out the parameters through sufficient statistics. Then in Chapter \ref{ChapterMCMC}, an adaptive Markov Chain Monte Carlo (MCMC) algorithm is proposed. In the case of a linear state space model and starting with a joint distribution over states, observations and parameters, an MCMC sampler is implemented with two phases. In the learning phase, a self-tuning sampler is used to learn the parameter mean and covariance structure. In the estimation phase, the parameter mean and covariance structure informs the proposal mechanism and is also used in a delayed-acceptance algorithm, which greatly improves sampling efficiency. Information on the resulting state of the system is given by a Gaussian mixture. In on-line mode, the algorithm is adaptive and uses a sliding window approach by cutting off historical data to accelerate sampling speed and to maintain appropriate acceptance rates. This algorithm is applied to joint state and parameters estimation in the case of irregularly sampled GPS time series data. 





